{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celonis\n",
    "from pycelonis import get_celonis\n",
    "from pycelonis.pql import PQL, PQLColumn, PQLFilter\n",
    "\n",
    "# Standard libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dates and Times\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from isoweek import Week\n",
    "\n",
    "# Maths, Models\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Others\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "%run Template_Func_Predictions_TS.ipynb\n",
    "# External data/GDP\n",
    "%run Template_Ext_Data.ipynb\n",
    "ext_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAM - DM name, table, column and filter to query input data from DM\n",
    "dm_name = 'TBD'\n",
    "datamodel = celonis.datamodels.find(dm_name)\n",
    "table_name = 'TBD'\n",
    "datamodel.tables.find(table_name).columns\n",
    "input_columns = [('col_name','pretty_name'),('col_name_2','pretty_name_2')]\n",
    "input_filter = \"FILTER TBD\"\n",
    "# Set columns of query\n",
    "query = PQL()\n",
    "for col_name,col_pretty_name in input_columns:\n",
    "    query += PQLColumn(col_name,col_pretty_name)\n",
    "# Set filter of query\n",
    "query += PQLFilter(input_filter)\n",
    "\n",
    "# Query input data from DM\n",
    "df = datamodel._get_data_frame(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: Run Predictions Model for Train df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predictions_model(df,ext_data,val_size_perc,to_adjust_years):\n",
    "    \n",
    "    ### PRE-PROCESSING\n",
    "    \n",
    "    # Reindex and print Df\n",
    "    df = df.reset_index()\n",
    "    # Clean data: fill empty weeks with 0 value\n",
    "    df=Fix_Data(df)\n",
    "    print(df.shape)\n",
    "    # Create Train Df\n",
    "    train_df = df.copy()\n",
    "        \n",
    "    # Cap the high outliers to a max value\n",
    "    # PARAM - Max value\n",
    "    max_outlier_value = 1000 #TBD\n",
    "    train_df = cap_outliers(train_df, max_outlier_value)\n",
    "    \n",
    "    # Adjust past data if baseline changed at date D\n",
    "    if to_adjust_years:\n",
    "        # PARAM - dates\n",
    "        change_date = 'TBD'\n",
    "        end_date = 'TBD'\n",
    "        train_df = adjust_baseline(train_df,change_date, end_date)\n",
    "    \n",
    "    # Plot\n",
    "    # PARAM - y margin for y axis\n",
    "    y_margin = 500000\n",
    "    plot_clean_y(df,train_df,max_outlier_value,y_margin)\n",
    "    \n",
    "    ### MODEL: Y = Trend + Seasonality + Residuals\n",
    "\n",
    "    ## Trend: Calculate, Model and Predict future values\n",
    "    \n",
    "    # PARAM - Trend window e.g. 52 if weekly TS with annual seasonality. 7 if daily TS with weekly seasonality\n",
    "    ts_seasonality = 52\n",
    "    train_df['Trend'] = calculate_trend(train_df,ts_seasonality, center=False)\n",
    "    # Plot Y and Trend\n",
    "    # PARAM - y axis\n",
    "    y_min = 0\n",
    "    y_max = 9000000\n",
    "    plot_y_trend(train_df,t,y_min,y_max)\n",
    "\n",
    "    # Use External data/GDP to fit and predict the Trend\n",
    "    print(train_df.dropna().shape)\n",
    "    train_df = combine_ext_data(train_df,ext_data,days_to_shift=1)\n",
    "    # PARAM - External Data/GDP column\n",
    "    exo_col_name = 'TBD'\n",
    "    exo_pretty_name = 'TBD'\n",
    "    \n",
    "    # Regression Trend on External data/GDP: define X=GDP and Y=Trend for regression model\n",
    "    X,Y = subsets_to_fit(train_df,exo_col_name,'Trend',val_size_perc)\n",
    "    # Plot Y, Trend and Exo Regr\n",
    "    # PARAM - y axis scale for External data/GDP\n",
    "    y_min_gdp = 100\n",
    "    y_max_gdp = 200\n",
    "    plot_y_trend_ext(train_df,exo_col_name,exo_pretty_name,y_min,y_max,y_min_gdp,y_max_gdp)\n",
    "    \n",
    "    # Fit Regression Y=Trend X=Exo\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    print(reg.coef_)\n",
    "    print(reg.intercept_)\n",
    "    print(reg.score(X,Y))\n",
    "    \n",
    "    # Predict Trend with fitted Regression\n",
    "    trend_pred_col_name = 'Predicted Trend'\n",
    "    X_F,train_df = predict_trend(train_df,exo_col_name,trend_pred_col_name)\n",
    "    # Plot Trend, External data/GDP and Predicted Trend\n",
    "    plot_y_pred_trend_ext(train_df,exo_col_name,X,Y,X_F,y_min,y_max,y_min_gdp,y_max_gdp)\n",
    "    print(train_df.head())\n",
    "\n",
    "    ## Calculate Seasonality\n",
    "    \n",
    "    # Calculate Y - Trend\n",
    "    train_df['Y - Trend'] = train_df[y_col_name]-train_df['Trend']\n",
    "    \n",
    "    # Get Seasonality by moving avg on Y - T, and average across years for 1 value per week of year\n",
    "    # PARAM - Moving avg window for S\n",
    "    window = 10\n",
    "    s = train_df['Y - Trend'].rolling(window=window,center=True).mean()\n",
    "    s = s.groupby(s.index.week).mean()\n",
    "    print(s.head(5))\n",
    "    print(s.tail(5))\n",
    "    \n",
    "    # Add Seasonality to df (Assign S to each week of each year)\n",
    "    # PARAM - S column name\n",
    "    seasonality_col_name = 'Seasonality'\n",
    "    train_df[seasonality_col_name] = np.nan\n",
    "    for i in train_df.index:\n",
    "        train_df.loc[i][seasonality_col_name] = s[i.week]\n",
    "        \n",
    "    # Should be not be required #\n",
    "    # Fix border dates with Null values\n",
    "    # PARAM - seasonsality period in days\n",
    "    seas_period_days = 52*7\n",
    "    delta = datetime.timedelta(days=-seas_period_days)\n",
    "    for i in train_df[train_df[seasonality_col_name].isnull()==True].index:\n",
    "        train_df.loc[i][seasonality_col_name] = train_df.loc[i+delta][seasonality_col_name]\n",
    "    \n",
    "    # Plot Y, T and S\n",
    "    plot_y_t_s_with_pred(train_df,trend_col_name,seasonality_col_name,trend_pred_col_name)\n",
    "    \n",
    "    ## Residuals: Calculate, Model and Predict future values\n",
    "\n",
    "    # Calculate R = Y - Trend - Season\n",
    "    train_df['Y - T - S'] = train_df[y_col_name]-train_df[trend_col_name]-train_df[seasonality_col_name]\n",
    "    # Create R df\n",
    "    # PARAM - R column name\n",
    "    r_col_name = 'Y - T - S'\n",
    "    r = train_df[r_col_name]\n",
    "    # Plot R\n",
    "    plot_r(train_df,r_col_name)\n",
    "\n",
    "    # R Study\n",
    "    # R shape\n",
    "    print(r.dropna().shape)\n",
    "    # Stationarity test\n",
    "    res = sm.tsa.adfuller(r.dropna(),regression='c')\n",
    "    print('p-value:{}'.format(res[1]))\n",
    "    # Verify that p value is low\n",
    "    \n",
    "    # ACF PACF on R\n",
    "    # PARAM - # lags for acf pacf\n",
    "    lags = 25\n",
    "    plot_acf_pacf_r(r,lags)\n",
    "    # Deduce ARMA(p,q) model for R\n",
    "\n",
    "    # Create R df for R Model\n",
    "    columns_to_drop = [y_col_name,exo_col_name]\n",
    "    col_to_rename = {'index':'Date'}\n",
    "    r_df = create_r_df(train_df,columns_to_drop,col_to_rename)\n",
    "\n",
    "    # Fit ARIMA Model on R for R predictions\n",
    "    # PARAM - p for AR, d for I, q for MA. Set using acf pacf plots above.\n",
    "    # P,D,Q,s can remain None.\n",
    "    # n_pred is # future points to forecast\n",
    "    # (Optional) model - to input an existing loaded model\n",
    "    # (Optional) exo - to input exogenous regressors\n",
    "    p,d,q = 3,0,3\n",
    "    P,D,Q,s = None,None,None,None\n",
    "    n_pred = 18\n",
    "    model = None\n",
    "    exo = None\n",
    "    model_r,results_df_r= get_results_with_val(df=r_df.dropna(),exo=exo,p,d,q,P,D,Q,s,model=model,n_predictions=n_pred,r_col_name,val_size_perc)\n",
    "\n",
    "    # Add Predicted R to df\n",
    "    # PARAM - R column name for df\n",
    "    r_col_name = 'Predicted R'\n",
    "    r_class_col_name = 'Predicted R Classification'\n",
    "    train_df = add_r(train_df,results_df_r,r_col_name,r_class_col_name)\n",
    "\n",
    "    ## Calculate Total Y Prediction = Predicted T + S + Predicted R\n",
    "    \n",
    "    # PARAM - y pred column names\n",
    "    y_pred_col_name = 'Y Prediction'\n",
    "    train_df = calc_y_pred(train_df,y_pred_col_name,trend_pred_col_name,seasonality_col_name,r_class_col_name)\n",
    "    print(train_df.tail(n=20))\n",
    "    # Plot and show Final Df with predictions\n",
    "    plot_final_y_t_s_r_with_pred(train_df,trend_col_name,seasonality_col_name,r_col_name,trend_pred_col_name,y_pred_col_name)\n",
    "    \n",
    "    # Show Final Df\n",
    "    train_df.head(n=10)\n",
    "    train_df.tail(n=10)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: Format Output for DM Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat results for Export to DM\n",
    "def prepare_export_df(train_df,output_col_names,y_pred_col_name):\n",
    "    export_df = pd.DataFrame(train_df[[y_col_name,y_pred_col_name,r_class_col_name]])\n",
    "    export_df.reset_index(inplace=True)\n",
    "    export_df.rename(columns=output_col_names\n",
    "                    ,inplace=True)\n",
    "    print(export_df.shape)\n",
    "    return export_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Predictions Model for selected Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INPUT Product Families\n",
    "#### OUTPUT Exported Predictions for DM\n",
    "\n",
    "## INPUTS\n",
    "subsets = ['Subset1','Subset2']\n",
    "subset_needs_adjusts = ['Subset2']\n",
    "subset_col_name = 'TBD'\n",
    "y_col_name = 'Y Value'\n",
    "val_size_perc = 0.2\n",
    "### OUTPUTS\n",
    "all_subset_results = {}\n",
    "all_subset_exports = {}\n",
    "output_col_names = {'index':'Date'\n",
    "                              ,y_col_name:'Actual Y Value'\n",
    "                              ,y_pred_col_name:'Predicted Y Value'\n",
    "                             ,r_class_col_name:'Classification'}\n",
    "\n",
    "### Run Predictions for each selected subset\n",
    "for subset in subsets:\n",
    "    print('Running model for ',subset)\n",
    "    # Check if subset needs baseline adjustment\n",
    "    to_adjust = False\n",
    "    if subset in subset_needs_adjusts:\n",
    "        to_adjust = True\n",
    "    \n",
    "    # Filter train df for subset\n",
    "    subset_train_df = train_df[train_df[subset_col_name]==prod_fam]\n",
    "    subset_train_df.drop(columns=[subset_col_name],inplace=True)\n",
    "    # Run Predictions model for this subset\n",
    "    subset_results = run_predictions_model(fm_train_df,ext_data,to_adjust)\n",
    "    # Store Output (subset Predictions)\n",
    "    all_subset_results[subset] = subset_results\n",
    "    print(subset,all_subset_results[subset].shape)\n",
    "    # Store export-version of the Output (subset Predictions)\n",
    "    all_subset_exports[subset] = prepare_export_df(subset_results,output_col_names,y_pred_col_name)\n",
    "\n",
    "print('Finished running predictions for all subsets, total output shape is ',all_subset_results[subset].shape)\n",
    "print('Subsets are ',all_subset_exports.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Results into single Export table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new 'subset name' column to the export-version of Predictions\n",
    "export_df = pd.DataFrame()\n",
    "for key in all_subset_exports:\n",
    "    print('Adding ',key,' value in new column')\n",
    "    subset_df = all_subset_exports[key]\n",
    "    subset_df[subset_col_name] = key\n",
    "    print('shape of subset export-version is ',subset_df.shape)\n",
    "    export_df = pd.concat([export_df,subset_df],axis=0)\n",
    "\n",
    "# Preview Export Df\n",
    "export_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify shape of export-version Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of export-version of all predictions\n",
    "export_df.shape\n",
    "# VALIDATION - should be # subsets x Timeframe (train, val and future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tail of export-version of predictions\n",
    "export_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to DM (Disable during WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DM for export\n",
    "dm = a.datamodel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export table to DM\n",
    "# PARAM - table name for exported predictions in DM\n",
    "dm_export_table_name = 'Predictions_Output'\n",
    "tablecombine = dm.push_table(export_df, dm_export_table_name, reload_datamodel = False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
